{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5f1a55e",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "Obtaining predictions as close as possible to $y$ target values requires the calculation of weights from the general\n",
    "LR equation. The feature matrix does not \n",
    "have an inverse because it is not square, so it is required to obtain an approximate solution, which can be\n",
    "obtained using the **Gram matrix** \n",
    "(multiplication of feature matrix ($X$) and its transpose ($X^T$)). The vector of weights or coefficients $w$ obtained with this\n",
    "formula is the closest possible solution to the LR system.\n",
    "\n",
    "Normal Equation:\n",
    "\n",
    "$w$ = $(X^TX)^{-1}X^Ty$\n",
    "\n",
    "Where:\n",
    "\n",
    "$X^TX$ is the Gram Matrix\n",
    "\n",
    "## Notes: Root Mean Squared Error (RMSE)\n",
    "\n",
    "* In the previous lesson we found out our predictions were a bit off from the actual target values in the training dataset. We need a way to quantify how good or bad the model is. This is where RMSE can be of help.\n",
    "* Root Mean Squared Error (RMSE) is a way to evaluate regression models. It measures the error associated with the model being evaluated. This numerical figure can then be used to compare models, enabling us to choose the one that gives the best predictions.\n",
    "\n",
    "$$RMSE = \\sqrt{ \\frac{1}{m} \\sum_{i=1}^{m} {(g(x_i) - y_i)^2}}$$\n",
    "\n",
    "- $g(x_i)$ is the prediction\n",
    "- $y_i$ is the actual value\n",
    "- $m$ is the number of observations in the dataset (i.e. cars)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
