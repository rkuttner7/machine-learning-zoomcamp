{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8200a2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autosave 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e7cddc",
   "metadata": {},
   "source": [
    "# 8. Neural networks and deep learning  \n",
    "  \n",
    "learn about neural nets and build a model for classifying images of clothes  \n",
    "\n",
    "# 8.1 Fashion classification  \n",
    "  \n",
    "Dataset:  \n",
    "  \n",
    "* Full: https://github.com/alexeygrigorev/clothing-dataset\n",
    "* Small: https://github.com/alexeygrigorev/clothing-dataset-small\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23486d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use http to avoid ssh credential errors in Colab\n",
    "#!git clone git@github.com:alexeygrigorev/clothing-dataset-small.git\n",
    "!git clone https://github.com/alexeygrigorev/clothing-dataset-small.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0e5903",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ./clothing-dataset-small/train/t-shirt/ | head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26452353",
   "metadata": {},
   "source": [
    "## 8.2 TensorFlow and Keras  \n",
    "  \n",
    "* Installing TensorFlow  \n",
    "* Loading images  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d20873d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf3e17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9238f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aeaad1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './clothing-dataset-small/train/t-shirt'\n",
    "#name = '5f0a3fa0-6a3d-4b68-b213-72766a643de7.jpg'\n",
    "name = '00003aeb-ace5-43bf-9a0c-dc31a03e9cd2.jpg'\n",
    "fullname = f'{path}/{name}'\n",
    "load_img(fullname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c974bfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can resize to fit expectation of model\n",
    "img = load_img(fullname, target_size=(299, 299))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633a6ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(img)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ceccbf",
   "metadata": {},
   "source": [
    "\n",
    "## 8.3 Pre-trained convolutional neural networks  \n",
    "  \n",
    "* Imagenet dataset: https://www.image-net.org/\n",
    "* Pre-trained models: https://keras.io/api/applications/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943ecb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.xception import Xception\n",
    "from tensorflow.keras.applications.xception import preprocess_input\n",
    "from tensorflow.keras.applications.xception import decode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c33112c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Xception(weights='imagenet', input_shape=(299, 299, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6557a33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to array\n",
    "X = np.array([x])\n",
    "\n",
    "# if multiple images {x, y, z} would be:\n",
    "#X = np.array([x, y, z])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db36bdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56570d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  apply necessary model pre-processing to get valid predictions\n",
    "X = preprocess_input(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7affaed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3997d208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions for top classes\n",
    "decode_predictions(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4112bb9",
   "metadata": {},
   "source": [
    "# 8.4 Convolutional neural networks  \n",
    "  \n",
    " * Types of layers: convolutional and dense\n",
    " * Convolutional layers and filters\n",
    " * Dense layers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87baa49b",
   "metadata": {},
   "source": [
    "# 8.5 Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df658c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: deprecacted. consider using `tensorflow.keras.utils.image_dataset_from_directory`\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fb33fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "train_ds = train_gen.flow_from_directory(\n",
    "    './clothing-dataset-small/train',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37d11db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class names inferred from named directories\n",
    "!ls -l clothing-dataset-small/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a6c44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e77b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = next(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7991a393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# {batch size, image width, image height, color channels}\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3056f993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# {batch size, multi-class size}\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef9fc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a3aebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "val_ds = val_gen.flow_from_directory(\n",
    "    './clothing-dataset-small/validation',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221a1696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain new model\n",
    "#  -- drop the 'Dense Layers' `include_top=False`\n",
    "base_model = Xception(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(150, 150, 3)\n",
    ")\n",
    "# Keep 'Convolutional Layers' static during retraining\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7c5569",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(150, input_size, 3))\n",
    "\n",
    "base = base_model(inputs)\n",
    "\n",
    "outputs = base\n",
    "\n",
    "model = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c59b6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# {batch size, 3D outcome field}\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b722c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inputs = keras.Input(shape=(input_size, input_size, 3))\n",
    "\n",
    "base = base_model(inputs, training=False)\n",
    "# Pooling: collapse 3D outcome prediction to vector\n",
    "#pooling = keras.layers.GlobalAveragePooling2D()\n",
    "#vectors = pooling(base)\n",
    "vectors = keras.layers.GlobalAveragePooling2D()(base)\n",
    "\n",
    "\n",
    "#outputs = vectors # prediction for all classes '2048'\n",
    "outputs = keras.layers.Dense(10)(vectors) # Fix 'Dense Layer' to 10 classes\n",
    "\n",
    "model = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1652078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate optimizer and loss function:\n",
    "\n",
    "learning_rate = 0.01\n",
    "optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "loss = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c1487b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(history.history['accuracy'], label='train') # training accuracy\n",
    "plt.plot(history.history['val_accuracy'], label='val')\n",
    "plt.xticks(np.arange(10))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f1d055",
   "metadata": {},
   "source": [
    "# 8.6 Adjusting the learning rate\n",
    "\n",
    "* What's the learning rate\n",
    "* Trying different values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435fd809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust learning rate  \n",
    "def make_model(learning_rate=0.01):\n",
    "    base_model = Xception(\n",
    "        weights='imagenet',\n",
    "        include_top=False, # drop the 'Dense Layers' to retrain \n",
    "        input_shape=(150, 150, 3)\n",
    "    )\n",
    "    # Keep 'Convolutional Layers' static during retraining\n",
    "    base_model.trainable = False\n",
    "\n",
    "    #########################################\n",
    "\n",
    "    # create architecture\n",
    "\n",
    "    inputs = keras.Input(shape=(150, 150, 3))\n",
    "    base = base_model(inputs, training=False)\n",
    "    # Pooling: collapse 3D outcome prediction to vector\n",
    "    #pooling = keras.layers.GlobalAveragePooling2D()\n",
    "    #vectors = pooling(base)\n",
    "    vectors = keras.layers.GlobalAveragePooling2D()(base)\n",
    "    #outputs = vectors # prediction for all classes '2048'\n",
    "    outputs = keras.layers.Dense(10)(vectors) # Fix 'Dense Layer' to 10 classes\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    \n",
    "    #########################################\n",
    "\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    loss = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=loss,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436436d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}\n",
    "\n",
    "#for lr in [0.0001, 0.001, 0.01, 0.1]:\n",
    "for lr in [0.001, 0.01]:\n",
    "    print(lr)\n",
    "\n",
    "    model = make_model(learning_rate=lr)\n",
    "    history = model.fit(train_ds, epochs=10, validation_data=val_ds)\n",
    "    scores[lr] = history.history\n",
    "\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26307d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lr, hist in scores.items():\n",
    "    #plt.plot(hist['accuracy'], label=('train=%s' % lr))\n",
    "    plt.plot(hist['val_accuracy'], label=('val=%s' % lr))\n",
    "\n",
    "plt.xticks(np.arange(10))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a04bfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e77843",
   "metadata": {},
   "source": [
    "# 8.7 Checkpointing\n",
    "\n",
    "* Saving the best model only\n",
    "* Training a model with callbacks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5854f830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model name (eg. 'xception_v1_01_0.771.h5')\n",
    "# formats:\n",
    "# * `02d` two digits (eg. \"05\", \"11\")\n",
    "# * `.3f` three decimal places (eg. \"0.001\", \"0.100\")\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "    'xception_v1_{epoch:02d}_{val_accuracy:.3f}.h5',\n",
    "    save_best_only=True, # only save model if epoch result is better\n",
    "    monitor='val_accuracy',\n",
    "    mode='max' # want largest scoring defined in 'monitor'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6478e6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "model = make_model(learning_rate=learning_rate)\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=10,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=[checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e6807b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# review saved models\n",
    "!ls -l "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c1457c",
   "metadata": {},
   "source": [
    "# 8.8 Adding more layers  \n",
    "  \n",
    "* Adding one inner dense layer  \n",
    "* Experimenting with different sizes of inner lay  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e311c11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(learning_rate=0.01, size_inner=100):\n",
    "    base_model = Xception(\n",
    "        weights='imagenet',\n",
    "        include_top=False, # drop the 'Dense Layers' to retrain \n",
    "        input_shape=(150, 150, 3)\n",
    "    )\n",
    "    # Keep 'Convolutional Layers' static during retraining\n",
    "    base_model.trainable = False\n",
    "\n",
    "    #########################################\n",
    "\n",
    "    # create architecture\n",
    "\n",
    "    inputs = keras.Input(shape=(150, 150, 3))\n",
    "    base = base_model(inputs, training=False)\n",
    "    # Pooling: collapse 3D outcome prediction to vector\n",
    "    #pooling = keras.layers.GlobalAveragePooling2D()\n",
    "    #vectors = pooling(base)\n",
    "    vectors = keras.layers.GlobalAveragePooling2D()(base)\n",
    "    \n",
    "    inner = keras.layers.Dense(size_inner, activation='relu')(vectors)\n",
    "    \n",
    "    #outputs = vectors # prediction for all classes '2048'\n",
    "    #outputs = keras.layers.Dense(10)(vectors) # Fix 'Dense Layer' to 10 classes\n",
    "    outputs = keras.layers.Dense(10)(inner)\n",
    "    \n",
    "    model = keras.Model(inputs, outputs)\n",
    "    \n",
    "    #########################################\n",
    "\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    loss = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=loss,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c6ce6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "scores = {}\n",
    "\n",
    "for size in [10, 100, 1000]:\n",
    "    print(size)\n",
    "\n",
    "    model = make_model(learning_rate=learning_rate, size_inner=size)\n",
    "    history = model.fit(train_ds, epochs=10, validation_data=val_ds)\n",
    "    scores[size] = history.history\n",
    "\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e28f616",
   "metadata": {},
   "source": [
    "# 8.9 Regularization and dropout  \n",
    "  \n",
    "* Regularizing by freezing a part of the network  \n",
    "* Adding dropout to our model  \n",
    "* Experimenting with different values  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc38fcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(learning_rate=0.01, size_inner=100, droprate=0.5):\n",
    "    base_model = Xception(\n",
    "        weights='imagenet',\n",
    "        include_top=False, # drop the 'Dense Layers' to retrain \n",
    "        input_shape=(150, 150, 3)\n",
    "    )\n",
    "    # Keep 'Convolutional Layers' static during retraining\n",
    "    base_model.trainable = False\n",
    "\n",
    "    #########################################\n",
    "\n",
    "    # create architecture\n",
    "\n",
    "    inputs = keras.Input(shape=(150, 150, 3))\n",
    "    base = base_model(inputs, training=False)\n",
    "    # Pooling: collapse 3D outcome prediction to vector\n",
    "    #pooling = keras.layers.GlobalAveragePooling2D()\n",
    "    #vectors = pooling(base)\n",
    "    vectors = keras.layers.GlobalAveragePooling2D()(base)\n",
    "\n",
    "    inner = keras.layers.Dense(size_inner, activation='relu')(vectors)\n",
    "\n",
    "    # dropout layer: random proportion of nodes dropped each training epoch\n",
    "    drop = keras.layers.Dropout(droprate)(inner)\n",
    "    \n",
    "    #outputs = vectors # prediction for all classes '2048'\n",
    "    #outputs = keras.layers.Dense(10)(vectors) # Fix 'Dense Layer' to 10 classes\n",
    "    outputs = keras.layers.Dense(10)(inner)\n",
    "    \n",
    "    model = keras.Model(inputs, outputs)\n",
    "    \n",
    "    #########################################\n",
    "\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    loss = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=loss,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9702c220",
   "metadata": {},
   "source": [
    "# 8.10 Data augmentation  \n",
    "  \n",
    "* Different data augmentations\n",
    "* Training a model with augmentations\n",
    "* How to select data augmentations?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7599714a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "     # adjust images to make training data more robust\n",
    "     shear_range=10.0,    \n",
    "     zoom_range=0.1,\n",
    "     vertical_flip=True,\n",
    ")\n",
    "\n",
    "train_ds = train_gen.flow_from_directory(\n",
    "    './clothing-dataset-small/train',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "val_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "val_ds = val_gen.flow_from_directory(\n",
    "    './clothing-dataset-small/validation',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a0ee1e",
   "metadata": {},
   "source": [
    "# 8.11 Training a larger model  \n",
    "  \n",
    "* Train a 299x299 model  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93e9946",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(\n",
    "    # image size (increase accuracy with larger image, slower training)\n",
    "    input_size = 150,\n",
    "    learning_rate=0.01, size_inner=100):\n",
    "    base_model = Xception(\n",
    "        weights='imagenet',\n",
    "        include_top=False, # drop the 'Dense Layers' to retrain \n",
    "        input_shape=(input_size, input_size, 3)\n",
    "    )\n",
    "    # Keep 'Convolutional Layers' static during retraining\n",
    "    base_model.trainable = False\n",
    "\n",
    "    #########################################\n",
    "\n",
    "    # create architecture\n",
    "\n",
    "    inputs = keras.Input(shape=(input_size, input_size, 3))\n",
    "    base = base_model(inputs, training=False)\n",
    "    # Pooling: collapse 3D outcome prediction to vector\n",
    "    #pooling = keras.layers.GlobalAveragePooling2D()\n",
    "    #vectors = pooling(base)\n",
    "    vectors = keras.layers.GlobalAveragePooling2D()(base)\n",
    "    \n",
    "    inner = keras.layers.Dense(size_inner, activation='relu')(vectors)\n",
    "    \n",
    "    #outputs = vectors # prediction for all classes '2048'\n",
    "    #outputs = keras.layers.Dense(10)(vectors) # Fix 'Dense Layer' to 10 classes\n",
    "    outputs = keras.layers.Dense(10)(inner)\n",
    "    \n",
    "    model = keras.Model(inputs, outputs)\n",
    "    \n",
    "    #########################################\n",
    "\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    loss = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=loss,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cccb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image size (eg. 150 -> 150 x 150)\n",
    "# -- (increase accuracy with larger image, slower training)\n",
    "input_size = 299,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86af1a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    # adjust images to make training data more robust\n",
    "    shear_range=10,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "train_ds = train_gen.flow_from_directory(\n",
    "    './clothing-dataset-small/train',\n",
    "    target_size=(input_size, input_size),\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "\n",
    "val_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "val_ds = train_gen.flow_from_directory(\n",
    "    './clothing-dataset-small/validation',\n",
    "    target_size=(input_size, input_size),\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd43e297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model name (eg. 'xception_v1_01_0.771.h5')\n",
    "# formats:\n",
    "# * `02d` two digits (eg. \"05\", \"11\")\n",
    "# * `.3f` three decimal places (eg. \"0.001\", \"0.100\")\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "    'xception_v4_1_{epoch:02d}_{val_accuracy:.3f}.h5',\n",
    "    save_best_only=True,  # only save model if epoch result is better\n",
    "    monitor='val_accuracy',\n",
    "    mode='max' # want largest scoring defined in 'monitor'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71824a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0005\n",
    "size = 100\n",
    "droprate = 0.2\n",
    "\n",
    "model = make_model(\n",
    "    input_size=input_size,\n",
    "    learning_rate=learning_rate,\n",
    "    size_inner=size,\n",
    "    droprate=droprate\n",
    ")\n",
    "\n",
    "history = model.fit(train_ds, epochs=50, validation_data=val_ds,\n",
    "                   callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b98adf",
   "metadata": {},
   "source": [
    "# 8.12 Using the model  \n",
    "  \n",
    "* Loading the model  \n",
    "* Evaluating the model  \n",
    "* Getting predictions  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bf692f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "\n",
    "from tensorflow.keras.applications.xception import preprocess_input\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6177ed56",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "test_ds = test_gen.flow_from_directory(\n",
    "    './clothing-dataset-small/test',\n",
    "    target_size=(299, 299),\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e8f3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('xception_v4_1_13_0.903.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10caa095",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb763759",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'clothing-dataset-small/test/pants/c8d21106-bbdb-4e8d-83e4-bf3d14e54c16.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218349d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_img(path, target_size=(299, 299))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9b7203",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(img)\n",
    "X = np.array([x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bea97ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1, 299, 299, 3)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ac1bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocess_input(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf78c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9ab34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\n",
    "    'dress',\n",
    "    'hat',\n",
    "    'longsleeve',\n",
    "    'outwear',\n",
    "    'pants',\n",
    "    'shirt',\n",
    "    'shoes',\n",
    "    'shorts',\n",
    "    'skirt',\n",
    "    't-shirt'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a916d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(zip(classes, pred[0]))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
