{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20faf2a3",
   "metadata": {},
   "source": [
    "# Solutions to homework week 9 - Deploy Models with AWS Lambda (Serverless)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c27faf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the model files from here: \n",
    "!wget https://github.com/alexeygrigorev/large-datasets/releases/download/hairstyle/hair_classifier_v1.onnx.data\n",
    "!wget https://github.com/alexeygrigorev/large-datasets/releases/download/hairstyle/hair_classifier_v1.onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e324d2",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "To be able to use this model, we need to know the name of the input and output nodes. \n",
    "\n",
    "What's the name of the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec96077d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "\n",
    "onnx_model_path = 'hair_classifier_v1.onnx'\n",
    "\n",
    "session = ort.InferenceSession(\n",
    "    onnx_model_path, providers=[\"CPUExecutionProvider\"]\n",
    ")\n",
    "input_name = session.get_inputs()[0].name\n",
    "output_name = session.get_outputs()[0].name\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b01a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe502fcd",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "Now we need to turn the image into numpy array and pre-process it. \n",
    "\n",
    "> Tip: Check the previous homework. What was the pre-processing \n",
    "> we did there?\n",
    "\n",
    "After the pre-processing, what's the value in the first pixel, the R channel?\n",
    "    transforms.Resize((200, 200)),\n",
    "    mean=[0.485, 0.456, 0.406],\n",
    "    std=[0.229, 0.224, 0.225]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54847ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the image\n",
    "from io import BytesIO\n",
    "from urllib import request\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "def download_image(url):\n",
    "    with request.urlopen(url) as resp:\n",
    "        buffer = resp.read()\n",
    "    stream = BytesIO(buffer)\n",
    "    img = Image.open(stream)\n",
    "    return img\n",
    "\n",
    "\n",
    "def prepare_image(img, target_size):\n",
    "    if img.mode != 'RGB':\n",
    "        img = img.convert('RGB')\n",
    "    img = img.resize(target_size, Image.NEAREST)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bb6c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_raw = download_image('https://habrastorage.org/webt/yf/_d/ok/yf_dokzqy3vcritme8ggnzqlvwa.jpeg')\n",
    "img = prepare_image(img_raw, target_size=(200, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0de68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(X):\n",
    "    # rescale range to [0:1] (from values in [0, 255])\n",
    "    X = X / 255.0\n",
    "\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "    # Normalize\n",
    "    X = (X - mean) / std\n",
    "\n",
    "    return X.astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07fd24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Convert to numpy array\n",
    "X_raw = np.array(img)\n",
    "\n",
    "X = preprocess(X_raw)\n",
    "\n",
    "#-- Images are represented as 3D arrays:\n",
    "# - Height × Width × Channels\n",
    "# - Channels: RGB (Red, Green, Blue)\n",
    "# - Each channel: 8 bits (0-255 values)\n",
    "X[0, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb740a7",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "Now let's apply this model to this image. What's the output of the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8b5a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_pytorch(X):\n",
    "    X = X / 255.0\n",
    "\n",
    "    mean = np.array([0.485, 0.456, 0.406]).reshape(1, 3, 1, 1)\n",
    "    std = np.array([0.229, 0.224, 0.225]).reshape(1, 3, 1, 1)\n",
    "\n",
    "    # Convert NHWC → NCHW\n",
    "    # from (batch, height, width, channels) to (batch, channels, height, width)\n",
    "    X = X.transpose(0, 3, 1, 2)\n",
    "\n",
    "    # Normalize\n",
    "    X = (X - mean) / std\n",
    "\n",
    "    return X.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0821b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_image_helper import create_preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9504bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = create_preprocessor(preprocess_pytorch, target_size=(200, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d95a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://habrastorage.org/webt/yf/_d/ok/yf_dokzqy3vcritme8ggnzqlvwa.jpeg'\n",
    "X = preprocessor.from_url(url)\n",
    "\n",
    "result = session.run([output_name], {input_name: X})\n",
    "float_predictions = result[0][0].tolist()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
