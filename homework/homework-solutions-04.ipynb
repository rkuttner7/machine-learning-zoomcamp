{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e161c48",
   "metadata": {},
   "source": [
    "# Solutions to homework week 4 - Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f68d891",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51da954f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check working directory to debug path to loading\n",
    "#import os\n",
    "#os.getcwd()\n",
    "\n",
    "# load the data\n",
    "df = pd.read_csv('../data/lead_scoring.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3d277e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.lead_source.value_counts().head()\n",
    "categorical_columns = ['lead_source', 'industry', 'employment_status', 'location']\n",
    "numeric_columns = ['number_of_courses_viewed', 'annual_income','interaction_count','lead_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d098cb79",
   "metadata": {},
   "source": [
    "### Data preparation\n",
    "\n",
    "* Check if the missing values are presented in the features.\n",
    "* If there are missing values:\n",
    "    * For caterogiral features, replace them with 'NA'\n",
    "    * For numerical features, replace with with 0.0 \n",
    "\n",
    "Split the data into 3 parts: train/validation/test with 60%/20%/20% distribution. Use `train_test_split` function for that with `random_state=1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "848a47c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lead_source                 128\n",
       "industry                    134\n",
       "number_of_courses_viewed      0\n",
       "annual_income               181\n",
       "employment_status           100\n",
       "location                     63\n",
       "interaction_count             0\n",
       "lead_score                    0\n",
       "converted                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f65eea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values_dict = {}\n",
    "for c in categorical_columns:\n",
    "    missing_values_dict[c] = 'NA'\n",
    "\n",
    "for n in numeric_columns:    \n",
    "    missing_values_dict[n] = 0\n",
    "# df.fillna(value=values)\n",
    "df = df.fillna(value=missing_values_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80f37509",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into 3 parts: train/validation/test with 60%/20%/20% distribution. \n",
    "# Use `train_test_split` function for that with `random_state=1`\n",
    "df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=1)\n",
    "# adjust proportion test size to be 20% of the remaining 80% after first split\n",
    "df_train, df_val = train_test_split(df_full_train, test_size=0.2/(0.8), random_state=1)\n",
    "\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "df_full_train = df_full_train.reset_index(drop=True)\n",
    "\n",
    "y_full_train = df_full_train.converted.values\n",
    "y_train = df_train.converted.values\n",
    "y_val = df_val.converted.values\n",
    "y_test = df_test.converted.values\n",
    "\n",
    "del df_full_train['converted']\n",
    "del df_train['converted']\n",
    "del df_val['converted']\n",
    "del df_test['converted']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c30a11",
   "metadata": {},
   "source": [
    "### Question 1: ROC AUC feature importance\n",
    "\n",
    "ROC AUC could also be used to evaluate feature importance of numerical variables. \n",
    "\n",
    "Let's do that\n",
    "\n",
    "* For each numerical variable, use it as score (aka prediction) and compute the AUC with the `y` variable as ground truth.\n",
    "* Use the training dataset for that\n",
    "\n",
    "\n",
    "If your AUC is < 0.5, invert this variable by putting \"-\" in front\n",
    "\n",
    "(e.g. `-df_train['engine_hp']`)\n",
    "\n",
    "AUC can go below 0.5 if the variable is negatively correlated with the target variable. You can change the direction of the correlation by negating this variable - then negative correlation becomes positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bce02552",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(df_train, y_train, features, C=1.0):    \n",
    "    # extract numpy array\n",
    "    X_train = df_train[features].values.reshape(-1, 1)\n",
    "\n",
    "    model = LogisticRegression(solver='lbfgs', C=C, max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def predict(df, model, features):\n",
    "    # extract numpy array\n",
    "    X = df[features].values.reshape(-1, 1)\n",
    "    y_pred = model.predict_proba(X)[:, 1]\n",
    "\n",
    "    return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4639d921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_of_courses_viewed  := 0.742\n",
      "annual_income  := 0.554\n",
      "interaction_count  := 0.697\n",
      "lead_score  := 0.623\n"
     ]
    }
   ],
   "source": [
    "for numeric_feature in numeric_columns:\n",
    "    model = train(df_train, y_train, features=numeric_feature)\n",
    "    y_pred = predict(df_val, model, features=numeric_feature)\n",
    "    score_auc = roc_auc_score(y_val, y_pred)\n",
    "    print(numeric_feature, \" := %.3f\"  % score_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c4eaa4",
   "metadata": {},
   "source": [
    "### Question 2: Training the model\n",
    "\n",
    "Apply one-hot-encoding using `DictVectorizer` and train the logistic regression with these parameters:\n",
    "\n",
    "```python\n",
    "LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)\n",
    "```\n",
    "\n",
    "What's the AUC of this model on the validation dataset? (round to 3 digits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e156feaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(df_train, y_train, C=1.0):\n",
    "    dicts = df_train[categorical_columns + numeric_columns].to_dict(orient='records')\n",
    "\n",
    "    dv = DictVectorizer(sparse=False)\n",
    "    X_train = dv.fit_transform(dicts)\n",
    "\n",
    "    model = LogisticRegression(solver='liblinear',C=C, max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    return dv, model\n",
    "\n",
    "def predict(df, dv, model):\n",
    "    dicts = df[categorical_columns + numeric_columns].to_dict(orient='records')\n",
    "\n",
    "    X = dv.transform(dicts)\n",
    "    y_pred = model.predict_proba(X)[:, 1]\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21344521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.817\n"
     ]
    }
   ],
   "source": [
    "dv, model = train(df_train, y_train)\n",
    "y_pred = predict(df_val, dv, model)\n",
    "score_auc = roc_auc_score(y_val, y_pred)\n",
    "print(\"%.3f\" % score_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e164e411",
   "metadata": {},
   "source": [
    "### Question 4: F1 score\n",
    "\n",
    "Precision and recall are conflicting - when one grows, the other goes down. That's why they are often combined into the F1 score - a metrics that takes into account both\n",
    "\n",
    "This is the formula for computing F1:\n",
    "\n",
    "$$F_1 = 2 \\cdot \\cfrac{P \\cdot R}{P + R}$$\n",
    "\n",
    "Where $P$ is precision and $R$ is recall.\n",
    "\n",
    "Let's compute F1 for all thresholds from 0.0 to 1.0 with increment 0.01\n",
    "\n",
    "At which threshold F1 is maximal?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9053ab46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_dataframe(y_val, y_pred):\n",
    "    scores = []\n",
    "\n",
    "    thresholds = np.linspace(0, 1, 101)\n",
    "\n",
    "    for t in thresholds:\n",
    "        actual_positive = (y_val == 1)\n",
    "        actual_negative = (y_val == 0)\n",
    "\n",
    "        predict_positive = (y_pred >= t)\n",
    "        predict_negative = (y_pred < t)\n",
    "\n",
    "        tp = (predict_positive & actual_positive).sum()\n",
    "        tn = (predict_negative & actual_negative).sum()\n",
    "\n",
    "        fp = (predict_positive & actual_negative).sum()\n",
    "        fn = (predict_negative & actual_positive).sum()\n",
    "\n",
    "        scores.append((t, tp, fp, fn, tn))\n",
    "\n",
    "    columns = ['threshold', 'tp', 'fp', 'fn', 'tn']\n",
    "    df_scores = pd.DataFrame(scores, columns=columns)\n",
    "\n",
    "    #df_scores['tpr'] = df_scores.tp / (df_scores.tp + df_scores.fn)\n",
    "    #df_scores['fpr'] = df_scores.fp / (df_scores.fp + df_scores.tn)\n",
    "    df_scores['precision'] = df_scores.tp / (df_scores.tp + df_scores.fp)\n",
    "    df_scores['recall'] = df_scores.tp / (df_scores.tp + df_scores.fn)\n",
    "    df_scores['f1'] = 2 * (df_scores.precision * df_scores.recall) / (df_scores.precision + df_scores.recall)\n",
    "    \n",
    "    return df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0709cdb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tn</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>171</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.583618</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.737069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.1</td>\n",
       "      <td>171</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.583618</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.737069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.2</td>\n",
       "      <td>171</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.583618</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.737069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.3</td>\n",
       "      <td>171</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.589655</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.741866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.4</td>\n",
       "      <td>171</td>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0.619565</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.765101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.5</td>\n",
       "      <td>164</td>\n",
       "      <td>81</td>\n",
       "      <td>7</td>\n",
       "      <td>41</td>\n",
       "      <td>0.669388</td>\n",
       "      <td>0.959064</td>\n",
       "      <td>0.788462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.6</td>\n",
       "      <td>150</td>\n",
       "      <td>53</td>\n",
       "      <td>21</td>\n",
       "      <td>69</td>\n",
       "      <td>0.738916</td>\n",
       "      <td>0.877193</td>\n",
       "      <td>0.802139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.7</td>\n",
       "      <td>106</td>\n",
       "      <td>25</td>\n",
       "      <td>65</td>\n",
       "      <td>97</td>\n",
       "      <td>0.809160</td>\n",
       "      <td>0.619883</td>\n",
       "      <td>0.701987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.8</td>\n",
       "      <td>64</td>\n",
       "      <td>6</td>\n",
       "      <td>107</td>\n",
       "      <td>116</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.374269</td>\n",
       "      <td>0.531120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.9</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>147</td>\n",
       "      <td>121</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.140351</td>\n",
       "      <td>0.244898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>171</td>\n",
       "      <td>122</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     threshold   tp   fp   fn   tn  precision    recall        f1\n",
       "0          0.0  171  122    0    0   0.583618  1.000000  0.737069\n",
       "10         0.1  171  122    0    0   0.583618  1.000000  0.737069\n",
       "20         0.2  171  122    0    0   0.583618  1.000000  0.737069\n",
       "30         0.3  171  119    0    3   0.589655  1.000000  0.741866\n",
       "40         0.4  171  105    0   17   0.619565  1.000000  0.765101\n",
       "50         0.5  164   81    7   41   0.669388  0.959064  0.788462\n",
       "60         0.6  150   53   21   69   0.738916  0.877193  0.802139\n",
       "70         0.7  106   25   65   97   0.809160  0.619883  0.701987\n",
       "80         0.8   64    6  107  116   0.914286  0.374269  0.531120\n",
       "90         0.9   24    1  147  121   0.960000  0.140351  0.244898\n",
       "100        1.0    0    0  171  122        NaN  0.000000       NaN"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_f1 = f1_dataframe(y_val, y_pred)\n",
    "\n",
    "# review every 10th record\n",
    "df_f1[::10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d0115fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold =  0.57 ; F1 =  0.812\n"
     ]
    }
   ],
   "source": [
    "f1_max = df_f1['f1'].max()\n",
    "f1_threshold = df_f1[f1_max == df_f1['f1']]['threshold']\n",
    "print(\"Threshold = \",\"%.2f\" % f1_threshold.values[0],\"; F1 = \", \"%.3f\" % f1_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8403b1",
   "metadata": {},
   "source": [
    "### Question 5: 5-Fold CV\n",
    "\n",
    "\n",
    "Use the `KFold` class from Scikit-Learn to evaluate our model on 5 different folds:\n",
    "\n",
    "```\n",
    "KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "```\n",
    "\n",
    "* Iterate over different folds of `df_full_train`\n",
    "* Split the data into train and validation\n",
    "* Train the model on train with these parameters: `LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)`\n",
    "* Use AUC to evaluate the model on validation\n",
    "\n",
    "How large is standard deviation of the scores across different folds?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571611a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "score = []\n",
    "\n",
    "for train_idx, val_idx in kfold.split(df_full_train):\n",
    "    df_train = df_full_train.iloc[train_idx]\n",
    "    df_val = df_full_train.iloc[val_idx]\n",
    "\n",
    "    y_train = y_full_train[train_idx] \n",
    "    y_val = y_full_train[val_idx] \n",
    "\n",
    "    dv, model = train(df_train, y_train, C=1)\n",
    "    y_pred = predict(df_val, dv, model)\n",
    "\n",
    "    auc = roc_auc_score(y_val, y_pred)\n",
    "    score.append(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f3503fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.822, +- 0.036\n"
     ]
    }
   ],
   "source": [
    "print('%.3f, +- %.3f' % (np.mean(score), np.std(score)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aabdd26",
   "metadata": {},
   "source": [
    "### Question 6: Hyperparameter Tuning\n",
    "\n",
    "Now let's use 5-Fold cross-validation to find the best parameter `C`\n",
    "\n",
    "* Iterate over the following `C` values: `[0.000001, 0.001, 1]`\n",
    "* Initialize `KFold` with the same parameters as previously\n",
    "* Use these parameters for the model: `LogisticRegression(solver='liblinear', C=C, max_iter=1000)`\n",
    "* Compute the mean score as well as the std (round the mean and std to 3 decimal digits)\n",
    "\n",
    "Which `C` leads to the best mean score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c2a571d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 5\n",
    "\n",
    "score_stats = {}\n",
    "\n",
    "for C in [0.000001, 0.001, 1]:\n",
    "    kfold = KFold(n_splits=n_splits, shuffle=True, random_state=1)\n",
    "\n",
    "    scores = []\n",
    "\n",
    "    for train_idx, val_idx in kfold.split(df_full_train):\n",
    "        df_train = df_full_train.iloc[train_idx]\n",
    "        df_val = df_full_train.iloc[val_idx]\n",
    "\n",
    "        y_train = y_full_train[train_idx] \n",
    "        y_val = y_full_train[val_idx] \n",
    "\n",
    "        dv, model = train(df_train, y_train, C=C)\n",
    "        y_pred = predict(df_val, dv, model)\n",
    "\n",
    "        auc = roc_auc_score(y_val, y_pred)\n",
    "        scores.append(auc)\n",
    "\n",
    "    #print('C=%s %.3f +- %.3f' % (C, np.mean(scores), np.std(scores)))\n",
    "    score_stats[C] = {\"mean\": np.mean(scores), \"std\": np.std(scores)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fc2a6be6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.000001</th>\n",
       "      <th>0.001000</th>\n",
       "      <th>1.000000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.560208</td>\n",
       "      <td>0.866878</td>\n",
       "      <td>0.822109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.023798</td>\n",
       "      <td>0.028746</td>\n",
       "      <td>0.035807</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0.000001  0.001000  1.000000\n",
       "mean  0.560208  0.866878  0.822109\n",
       "std   0.023798  0.028746  0.035807"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(score_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e168a91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
