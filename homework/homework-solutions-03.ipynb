{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea53c339",
   "metadata": {},
   "source": [
    "# Solutions to homework week 3 - logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fda5d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a31057d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check working directory to debug path to loading\n",
    "#import os\n",
    "#os.getcwd()\n",
    "\n",
    "# load the data\n",
    "df = pd.read_csv('../data/lead_scoring.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0dc7cbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lead_source                  object\n",
       "industry                     object\n",
       "number_of_courses_viewed      int64\n",
       "annual_income               float64\n",
       "employment_status            object\n",
       "location                     object\n",
       "interaction_count             int64\n",
       "lead_score                  float64\n",
       "converted                     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76e2267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.lead_source.value_counts().head()\n",
    "categorical_columns = ['lead_source', 'industry', 'employment_status', 'location']\n",
    "numeric_columns = ['number_of_courses_viewed', 'annual_income','interaction_count','lead_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884c4a03",
   "metadata": {},
   "source": [
    "### Data preparation\n",
    "\n",
    "* Check if the missing values are presented in the features.\n",
    "* If there are missing values:\n",
    "    * For caterogiral features, replace them with 'NA'\n",
    "    * For numerical features, replace with with 0.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3f083201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lead_source                 128\n",
       "industry                    134\n",
       "number_of_courses_viewed      0\n",
       "annual_income               181\n",
       "employment_status           100\n",
       "location                     63\n",
       "interaction_count             0\n",
       "lead_score                    0\n",
       "converted                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c325435",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values_dict = {}\n",
    "for c in categorical_columns:\n",
    "    missing_values_dict[c] = 'NA'\n",
    "\n",
    "for n in numeric_columns:    \n",
    "    missing_values_dict[n] = 0\n",
    "# df.fillna(value=values)\n",
    "df = df.fillna(value=missing_values_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f8c9f071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lead_source                 0\n",
       "industry                    0\n",
       "number_of_courses_viewed    0\n",
       "annual_income               0\n",
       "employment_status           0\n",
       "location                    0\n",
       "interaction_count           0\n",
       "lead_score                  0\n",
       "converted                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b81da7",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "What is the most frequent observation (mode) for the column `industry`?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2295ba0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "industry\n",
       "retail           203\n",
       "finance          200\n",
       "other            198\n",
       "healthcare       187\n",
       "education        187\n",
       "technology       179\n",
       "manufacturing    174\n",
       "NA               134\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.industry.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093679ba",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "Create the [correlation matrix](https://www.google.com/search?q=correlation+matrix) for the numerical features of your dataset. \n",
    "In a correlation matrix, you compute the correlation coefficient between every pair of features.\n",
    "\n",
    "What are the two features that have the biggest correlation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "365ca42a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number_of_courses_viewed</th>\n",
       "      <th>annual_income</th>\n",
       "      <th>interaction_count</th>\n",
       "      <th>lead_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>number_of_courses_viewed</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>-0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>annual_income</th>\n",
       "      <td>0.010</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>interaction_count</th>\n",
       "      <td>-0.024</td>\n",
       "      <td>0.027</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lead_score</th>\n",
       "      <td>-0.005</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.010</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          number_of_courses_viewed  annual_income  \\\n",
       "number_of_courses_viewed                     1.000          0.010   \n",
       "annual_income                                0.010          1.000   \n",
       "interaction_count                           -0.024          0.027   \n",
       "lead_score                                  -0.005          0.016   \n",
       "\n",
       "                          interaction_count  lead_score  \n",
       "number_of_courses_viewed             -0.024      -0.005  \n",
       "annual_income                         0.027       0.016  \n",
       "interaction_count                     1.000       0.010  \n",
       "lead_score                            0.010       1.000  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[numeric_columns].corr().round(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08929205",
   "metadata": {},
   "source": [
    "### Split the data\n",
    "\n",
    "* Split your data in train/val/test sets with 60%/20%/20% distribution.\n",
    "* Use Scikit-Learn for that (the `train_test_split` function) and set the seed to `42`.\n",
    "* Make sure that the target value `y` is not in your dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d8a78235",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a58ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "# adjust proportion test size to be 20% of total, after reduction by 20%\n",
    "df_train, df_val = train_test_split(df_full_train, test_size=0.2/0.8, random_state=1)\n",
    "\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "df_full_train = df_full_train.reset_index(drop=True)\n",
    "\n",
    "y_full_train = df_full_train.converted.values\n",
    "y_train = df_train.converted.values\n",
    "y_val = df_val.converted.values\n",
    "y_test = df_test.converted.values\n",
    "\n",
    "del df_full_train['converted']\n",
    "del df_train['converted']\n",
    "del df_val['converted']\n",
    "del df_test['converted']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3195d4",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "* Calculate the mutual information score between `y` and other categorical variables in the dataset. Use the training set only.\n",
    "* Round the scores to 2 decimals using `round(score, 2)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e5485e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mutual_info_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7ed08762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lead_source          0.03\n",
       "employment_status    0.02\n",
       "industry             0.01\n",
       "location             0.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mutual_info_churn_score(series):\n",
    "    return mutual_info_score(series, y_train)\n",
    "\n",
    "mi = df_train[categorical_columns].apply(mutual_info_churn_score)\n",
    "mi.sort_values(ascending=False).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf2d8fe",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "* Now let's train a logistic regression.\n",
    "* Remember that we have several categorical variables in the dataset. Include them using one-hot encoding.\n",
    "* Fit the model on the training dataset.\n",
    "    - To make sure the results are reproducible across different versions of Scikit-Learn, fit the model with these parameters:\n",
    "    - `model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)`\n",
    "* Calculate the accuracy on the validation dataset and round it to 2 decimal digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d8dc341e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "68bfb705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate class vectorizer\n",
    "dv = DictVectorizer(sparse=False)\n",
    "\n",
    "train_dict = df_train[categorical_columns + numeric_columns].to_dict(orient='records')\n",
    "X_train = dv.fit_transform(train_dict)\n",
    "\n",
    "val_dict = df_val[categorical_columns + numeric_columns].to_dict(orient='records')\n",
    "# validation uses the one-hot-encoding fit from training\n",
    "X_val = dv.transform(val_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e7138f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3fd2a7ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.74)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# probility of event is second column\n",
    "y_pred = model.predict_proba(X_val)[:,1]\n",
    "\n",
    "# proportion of records correctly identified\n",
    "accuracy_all_features = (y_val == (y_pred >= 0.5)).mean()\n",
    "accuracy_all_features.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b13013",
   "metadata": {},
   "source": [
    "### Question 5 \n",
    "\n",
    "* Let's find the least useful feature using the *feature elimination* technique.\n",
    "* Train a model using the same features and parameters as in Q4 (without rounding).\n",
    "* Now exclude each feature from this set and train a model without it. Record the accuracy for each model.\n",
    "* For each feature, calculate the difference between the original accuracy and the accuracy without the feature. \n",
    "\n",
    "Which of following feature has the smallest difference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f178a057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lead_score           0.003413\n",
       "industry             0.010239\n",
       "employment_status    0.051195\n",
       "dtype: float64"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def model_fit(features):\n",
    "    # instantiate class vectorizer\n",
    "    dv = DictVectorizer(sparse=False)\n",
    "\n",
    "    train_dict = df_train[features].to_dict(orient='records')\n",
    "    X_train = dv.fit_transform(train_dict)\n",
    "\n",
    "    val_dict = df_val[features].to_dict(orient='records')\n",
    "    # validation uses the one-hot-encoding fit from training\n",
    "    X_val = dv.transform(val_dict)\n",
    "\n",
    "    model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # probility of event is second column\n",
    "    y_pred = model.predict_proba(X_val)[:,1]\n",
    "\n",
    "    # proportion of records correctly identified\n",
    "    return((y_val == (y_pred >= 0.5)).mean())\n",
    "\n",
    "def model_feature_loop(features):\n",
    "    accuracy_dict = {}\n",
    "    accuracy_list = []\n",
    "\n",
    "    for feature_dropped in features:\n",
    "        feature_subset = features.copy()\n",
    "        feature_subset.remove(feature_dropped)\n",
    "        \n",
    "        accuracy_dict[feature_dropped] = model_fit(feature_subset)\n",
    "        accuracy_list.append(model_fit(feature_subset))\n",
    "        \n",
    "    return(accuracy_dict)\n",
    "\n",
    "accuracy_dict = model_feature_loop(categorical_columns + numeric_columns)\n",
    "\n",
    "accuracy_series = pd.Series(accuracy_dict)\n",
    "\n",
    "accuracy_abs_diff = abs(accuracy_all_features - accuracy_series)\n",
    "\n",
    "# question interested in differenct in only subset of features\n",
    "accuracy_abs_diff.loc[['industry', 'employment_status', 'lead_score']].sort_values(ascending=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07490a0",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "* Now let's train a regularized logistic regression.\n",
    "* Let's try the following values of the parameter `C`: `[0.01, 0.1, 1, 10, 100]`.\n",
    "* Train models using all the features as in Q4.\n",
    "* Calculate the accuracy on the validation dataset and round it to 3 decimal digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "4e42c08e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.01</th>\n",
       "      <td>0.744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.10</th>\n",
       "      <td>0.744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.00</th>\n",
       "      <td>0.744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.00</th>\n",
       "      <td>0.744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100.00</th>\n",
       "      <td>0.744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        accuracy\n",
       "0.01       0.744\n",
       "0.10       0.744\n",
       "1.00       0.744\n",
       "10.00      0.744\n",
       "100.00     0.744"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_list = []\n",
    "r_parameters = [0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "features = categorical_columns + numeric_columns\n",
    "\n",
    "for r in r_parameters:\n",
    "    # instantiate class vectorizer\n",
    "    dv = DictVectorizer(sparse=False)\n",
    "\n",
    "    train_dict = df_train[features].to_dict(orient='records')\n",
    "    X_train = dv.fit_transform(train_dict)\n",
    "\n",
    "    val_dict = df_val[features].to_dict(orient='records')\n",
    "    # validation uses the one-hot-encoding fit from training\n",
    "    X_val = dv.transform(val_dict)\n",
    "\n",
    "    model = LogisticRegression(solver='liblinear', C=r, max_iter=1000, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # probility of event is second column\n",
    "    y_pred = model.predict_proba(X_val)[:,1]\n",
    "\n",
    "    # proportion of records correctly identified\n",
    "    accuracy_r = (y_val == (y_pred >= 0.5)).mean()\n",
    "\n",
    "    accuracy_list.append(accuracy_r.round(3))\n",
    "\n",
    "pd.DataFrame(data = accuracy_list, index = r_parameters, columns = ['accuracy']).sort_values('accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f185064f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
